{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Report: Linear Regression and Regularized Models\n",
    "\n",
    "#### Overview\n",
    "\n",
    "I employed multiple approaches to predict house prices, including standard Linear Regression and several combinations of regularized models: Ridge, Lasso, and ElasticNet. The data was split into training and validation sets, scaled, and used for model training and evaluation.\n",
    "\n",
    "#### Results\n",
    "\n",
    "- **Linear Regression**:\n",
    "  - **MSE**: 23.48673519542582\n",
    "  - **R² Score**: 0.7390315860425438\n",
    "\n",
    "- **Average of Ridge, Lasso, and ElasticNet**:\n",
    "  - **MSE**: 23.48673519542582\n",
    "  - **R² Score**: 0.7390315860425438\n",
    "\n",
    "**Kaggle Scores:**\n",
    "- **Linear Regression**:\n",
    "  - Private Score: 4.86599\n",
    "  - Public Score: 4.81636\n",
    "\n",
    "- **Average of Ridge, Lasso, and ElasticNet**:\n",
    "  - Private Score: 4.84934\n",
    "  - Public Score: 4.75777\n",
    "\n",
    "#### Report and Analysis\n",
    "\n",
    "To improve performance, I experimented with various combinations of Ridge, Lasso, and ElasticNet models. The best results were achieved by averaging the predictions from these regularized models.\n",
    "\n",
    "The slight improvement in performance with the average of the regularized models, compared to the standard Linear Regression, is due to the nature of regularization. Ridge, Lasso, and ElasticNet incorporate penalties that help control model complexity and prevent overfitting. By averaging the predictions from these models, I leveraged their individual strengths, which led to a marginal improvement in prediction accuracy. However, the improvement was modest, indicating that while regularization helps, its effect in this case was not dramatic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load training data\n",
    "train_file_path = # Add training data file path here\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "\n",
    "# Load testing data\n",
    "test_file_path = # Add testing data file path here\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "# Extract features (X) and target (y) from the training data\n",
    "X = train_data.drop(columns=['ID', 'medv'])\n",
    "y = train_data['medv']  # Target variable\n",
    "\n",
    "# Extract features (X) from the test data (excluding ID column)\n",
    "X_test = test_data.drop(columns=['ID'], errors='ignore')\n",
    "\n",
    "# Split the training data into train and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and fit the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_valid_pred = model.predict(X_valid_scaled)\n",
    "mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "r2 = r2_score(y_valid, y_valid_pred)\n",
    "\n",
    "print(f\"Linear Regression - MSE: {mse}, R2 Score: {r2}\")\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Save predictions to CSV\n",
    "output = pd.DataFrame({'ID': test_data['ID'], 'medv': y_test_pred})\n",
    "output_file_path = # Add the path to which you want to save the file\n",
    "output.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # For data management\n",
    "from sklearn.model_selection import train_test_split # For splitting the data\n",
    "from sklearn.preprocessing import StandardScaler # I used this for scaling the data\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet # As mentioned in the article, these can be used to improve our performance, I took average as explained later\n",
    "from sklearn.metrics import mean_squared_error, r2_score # For error identification\n",
    "\n",
    "# We load the training data present in a csv file use a standard pandas function\n",
    "train_file_path = # Add training data file path here \n",
    "train_data = pd.read_csv(train_file_path)\n",
    "\n",
    "# We load the testing data in the same manner\n",
    "test_file_path = # Add testing data file path here \n",
    "test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "# We extract the features (X) and target (y) from the training data\n",
    "X = train_data.drop(columns=['ID', 'medv'])  # We drop 'ID' and 'medv' columns, ID is not useful for our purpose predicting the values on the testing data\n",
    "y = train_data['medv']  # We set the target variable, i.e, the expected output, our code will try to create a linear function with multiple variables being the columns other than the house price and the house price is the output.\n",
    "\n",
    "# We extract the features (X) from the test data, excluding the ID column\n",
    "X_test = test_data.drop(columns=['ID'], errors='ignore')\n",
    "\n",
    "# We split the training data into training and validation sets in the standard 80% to 20% ratio\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "# We scale the features for standardisation of the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# We initialize the models we want to use, we can use the average of all three to get the best method, I uploaded all individually and in different combinations but got the best result using the average of all 3.\n",
    "# Alpha and l1_ratio are regularization parameters used to keep overfitting in check, I used chat-gpt suggested values of alpha here.\n",
    "models = {\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=0.1),\n",
    "    'ElasticNet': ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "}  \n",
    "\n",
    "# We define a function to evaluate each model, mse stands for mean-squared error and focuses on how different the predicted values are from the expected values\n",
    "# The r2_score focuses more on how the data works with variability of the input\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_valid, y_valid):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_valid)\n",
    "    mse = mean_squared_error(y_valid, y_pred)\n",
    "    r2 = r2_score(y_valid, y_pred)\n",
    "    return mse, r2\n",
    "\n",
    "# We create a DataFrame to store the predictions from each model\n",
    "predictions_df = pd.DataFrame()\n",
    "for name, model in models.items():\n",
    "    # We train the model on the training set and make predictions on the test set after our model has been trained\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    # We store the predictions in the DataFrame for the purpose of saving to csv\n",
    "    predictions_df[name] = pred_test\n",
    "\n",
    "# We calculate the average of the predictions from the three models\n",
    "average_prediction = predictions_df.mean(axis=1)\n",
    "\n",
    "# We save the average predictions to a CSV file\n",
    "output = pd.DataFrame({'ID': test_data['ID'], 'medv': average_prediction})\n",
    "output_file_path = # Add the path to which you want to save the file\n",
    "output.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Average of all 3 - MSE: {mse}, R2 Score: {r2}\")\n",
    "\n",
    "# We print confirmation that the predictions have been saved\n",
    "print(f\"Predictions saved to {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
